# Recursos Utilizados - Data Mart de Marketing Bancario

## üõ†Ô∏è Herramientas y Tecnolog√≠as

### Core Technologies
- **dbt (data build tool)**: Framework principal para transformaciones de datos
  - Versi√≥n: 1.10.7
  - Prop√≥sito: ETL/ELT, testing, documentaci√≥n
  - Archivo: `dbt_project.yml`

- **dbt Cloud**: Plataforma cloud para desarrollo y deployment
  - Prop√≥sito: CI/CD, scheduling, documentaci√≥n
  - Configuraci√≥n: Jobs autom√°ticos, notificaciones

- **BigQuery**: Data warehouse serverless
  - Prop√≥sito: Almacenamiento y procesamiento de datos
  - Location: US
  - Project: dusa-prj-sandbox

### Dependencias de dbt
```yaml
# packages.yml
packages:
  - package: calogica/dbt_utils
    version: 1.1.1
```

### Herramientas de Desarrollo
- **Git**: Control de versiones
- **GitHub/GitLab**: Repositorio remoto
- **Python**: Scripts de utilidad
- **SQL**: Transformaciones de datos

## üìä Datasets y Fuentes de Datos

### Datasets Originales
1. **bank-full.csv** (4,521 registros)
   - Fuente: UCI Machine Learning Repository
   - Descripci√≥n: Dataset principal de marketing bancario
   - Campos: 17 variables demogr√°ficas y de campa√±a

2. **bank-additional-full.csv** (4,119 registros)
   - Fuente: UCI Machine Learning Repository
   - Descripci√≥n: Dataset con contexto socioecon√≥mico
   - Campos: 21 variables (incluye 4 variables econ√≥micas adicionales)

### Datasets Transformados
1. **Raw Layer** (`raw.bank_marketing`, `raw.bank_additional`)
   - Prop√≥sito: Datos originales sin transformar
   - Ubicaci√≥n: BigQuery

2. **Staging Layer** (`stg_bank_marketing`, `stg_bank_additional`)
   - Prop√≥sito: Limpieza y estandarizaci√≥n
   - Tipo: Views en BigQuery

3. **Intermediate Layer** (`int_customer_profiles`, `int_campaign_performance`)
   - Prop√≥sito: Transformaciones de negocio
   - Tipo: Tables en BigQuery

4. **Marts Layer** (`fct_marketing_conversions`, `dim_customer_segments`)
   - Prop√≥sito: Datos finales para an√°lisis
   - Tipo: Tables en BigQuery

## üîß Scripts y Automatizaci√≥n

### Scripts de Configuraci√≥n
1. **`scripts/dataplex_integration.sql`**
   - Prop√≥sito: Configuraci√≥n de gobernanza de datos
   - Funcionalidad: Entidades, pol√≠ticas, etiquetas

### Scripts de Carga de Datos
```bash
# Comandos bq load para cargar datos raw
bq load --location=US --source_format=CSV \
  dusa-prj-sandbox:raw.bank_marketing \
  bank-full.csv \
  [schema_definition]

bq load --location=US --source_format=CSV \
  dusa-prj-sandbox:raw.bank_additional \
  bank-additional-full.csv \
  [schema_definition]
```

### Scripts de Creaci√≥n de Datasets
```sql
-- scripts/create_datasets.sql (eliminado, integrado en README)
CREATE SCHEMA IF NOT EXISTS `dusa-prj-sandbox.raw`
CREATE SCHEMA IF NOT EXISTS `dusa-prj-sandbox.bank_marketing_dev_staging`
CREATE SCHEMA IF NOT EXISTS `dusa-prj-sandbox.bank_marketing_dev_intermediate`
CREATE SCHEMA IF NOT EXISTS `dusa-prj-sandbox.bank_marketing_dev_marts`
```

## üìÅ Estructura de Archivos

### Archivos de Configuraci√≥n
- `dbt_project.yml`: Configuraci√≥n principal del proyecto
- `packages.yml`: Dependencias de dbt
- `requirements.txt`: Dependencias de Python
- `.gitignore`: Archivos a ignorar en Git

### Modelos dbt
```
models/
‚îú‚îÄ‚îÄ staging/
‚îÇ   ‚îú‚îÄ‚îÄ stg_bank_marketing.sql
‚îÇ   ‚îî‚îÄ‚îÄ stg_bank_additional.sql
‚îú‚îÄ‚îÄ intermediate/
‚îÇ   ‚îú‚îÄ‚îÄ int_customer_profiles.sql
‚îÇ   ‚îî‚îÄ‚îÄ int_campaign_performance.sql
‚îú‚îÄ‚îÄ marts/
‚îÇ   ‚îî‚îÄ‚îÄ marketing/
‚îÇ       ‚îú‚îÄ‚îÄ fct_marketing_conversions.sql
‚îÇ       ‚îî‚îÄ‚îÄ dim_customer_segments.sql
‚îú‚îÄ‚îÄ schema.yml
‚îî‚îÄ‚îÄ sources.yml
```

### Tests
```
tests/
‚îú‚îÄ‚îÄ test_age_group_distribution.sql
‚îî‚îÄ‚îÄ test_conversion_rate_consistency.sql
```

### Macros
```
macros/
‚îî‚îÄ‚îÄ quality_monitoring.sql
```

### Documentaci√≥n
```
docs/
‚îú‚îÄ‚îÄ CONFIGURACION_FINAL.md
‚îî‚îÄ‚îÄ models.md
```

## üîÑ Jobs de dbt Cloud

### Job 1: Build Completo
- **Comandos**: `dbt deps`, `dbt build --full-refresh`
- **Schedule**: `0 2 * * *` (Diario a las 2 AM)
- **Timeout**: 3600 segundos
- **Prop√≥sito**: Reconstrucci√≥n completa del pipeline

### Job 2: Tests
- **Comandos**: `dbt deps`, `dbt test`
- **Schedule**: `0 3 * * *` (Diario a las 3 AM)
- **Timeout**: 1800 segundos
- **Prop√≥sito**: Validaci√≥n de calidad de datos

### Job 3: Documentaci√≥n
- **Comandos**: `dbt deps`, `dbt docs generate`, `dbt docs serve --port 8080`
- **Schedule**: `0 4 * * 0` (Semanal los domingos)
- **Timeout**: 900 segundos
- **Prop√≥sito**: Generaci√≥n de documentaci√≥n

## üß™ Tests Implementados

### Tests de Schema
- **Unicidad**: `unique` en `contact_id`
- **Completitud**: `not_null` en campos obligatorios
- **Valores v√°lidos**: `accepted_values` para categor√≠as

### Tests Personalizados
- **`test_age_group_distribution.sql`**: Verifica distribuci√≥n de grupos de edad
- **`test_conversion_rate_consistency.sql`**: Valida consistencia de tasas de conversi√≥n

### Macros de Monitoreo
- **`quality_monitoring()`**: M√©tricas de calidad de datos
- **`quality_alerts()`**: Alertas autom√°ticas
- **`performance_metrics()`**: M√©tricas de rendimiento

## üîí Servicios de Gobernanza (Opcional)

### Dataplex
- **API**: `dataplex.googleapis.com`
- **Prop√≥sito**: Clasificaci√≥n y gobernanza de datos
- **Configuraci√≥n**: `scripts/dataplex_integration.sql`

### BigQuery IAM
- **Roles requeridos**:
  - `roles/bigquery.dataEditor`
  - `roles/bigquery.jobUser`
  - `roles/dataplex.dataOwner` (opcional)

## üìä M√©tricas y KPIs Calculados

### M√©tricas de Conversi√≥n
- Tasa de conversi√≥n global
- Tasa de conversi√≥n por segmento
- Tasa de conversi√≥n por campa√±a

### Segmentaci√≥n
- Grupos de edad: Young, Adult, Middle Age, Senior
- Perfiles de riesgo: High, Medium, Low, No Risk
- Segmentos de cliente: Young Professional, White Collar, Retired, Blue Collar

### M√©tricas de Campa√±a
- Duraci√≥n de llamadas (Short, Medium, Long)
- Frecuencia de contactos
- Timing de campa√±as

## üîß Comandos de Ejecuci√≥n

### Comandos dbt Principales
```bash
# Instalar dependencias
dbt deps

# Ejecutar todo el pipeline
dbt build

# Ejecutar solo staging
dbt run --select staging

# Ejecutar tests
dbt test

# Generar documentaci√≥n
dbt docs generate
dbt docs serve
```

### Comandos de Verificaci√≥n
```sql
-- Verificar datos en staging
SELECT COUNT(*) FROM `dusa-prj-sandbox.bank_marketing_dev_staging.stg_bank_marketing`;

-- Verificar m√©tricas de conversi√≥n
SELECT AVG(conversion_rate) FROM `dusa-prj-sandbox.bank_marketing_dev_marts.fct_marketing_conversions`;
```

## üìö Recursos de Referencia

### Documentaci√≥n Oficial
- [dbt Documentation](https://docs.getdbt.com/)
- [dbt Cloud Documentation](https://docs.getdbt.com/docs/cloud)
- [BigQuery Documentation](https://cloud.google.com/bigquery/docs)
- [Dataplex Documentation](https://cloud.google.com/dataplex/docs)

### Datasets Originales
- [UCI Bank Marketing Dataset](https://archive.ics.uci.edu/ml/datasets/Bank+Marketing)

### Comunidad
- [dbt Community](https://community.getdbt.com/)
- [dbt Slack](https://community.getdbt.com/slack)

---

**Nota**: Todos los recursos est√°n configurados para funcionar en conjunto en un entorno de dbt Cloud con BigQuery. Los archivos CSV originales no est√°n incluidos en el repositorio por optimizaci√≥n, pero se proporcionan instrucciones para su carga en BigQuery.